{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Munge the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "1. [Load the Data](#load_the_data)\n",
    "\n",
    "2. [Combine all of the Data into one Comprehensive Pandas DataFrame](#combine)  \n",
    "    a. [Combine all the Ogishi data](#ogishi)  \n",
    "    b. [Add the HIV Brain Sequence Database Data](#brain_db)  \n",
    "    c. [Add the Holman Validation Data](#holman)  \n",
    "      \n",
    "3. [Add New Columns to Summarize and Concatenate Pertinant Information](#new_cols)  \n",
    "    a. [Sequences](#sequences)  \n",
    "    b. [HAND Status](#hand_status)  \n",
    "    c. [Tissue ID](#tissue_id)   \n",
    "    d. [Patient ID](#patient_id) \n",
    "    \n",
    "4. [Reduce to only the Data We Want](#reduce)\n",
    "\n",
    "5. [Save the Data to csv](#save)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "from functools import reduce\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_the_data'></a>\n",
    "## 1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the fasta files and create a list of ids and a list of sequences.\n",
    "Files = {}\n",
    "Files['C2V3C3_HANDDatabase_AA.fasta'] = {'filePath': './data/OgishiAndYotsuyanagi/C2V3C3_HANDDatabase_AA.fasta'}\n",
    "Files['C2V3C3_LANL_AA.fasta'] = {'filePath': './data/OgishiAndYotsuyanagi/C2V3C3_LANL_AA.fasta'}\n",
    "Files['C2V3C3_Metadataset_AA.fasta'] = {'filePath': './data/OgishiAndYotsuyanagi/C2V3C3_Metadataset_AA.fasta'}\n",
    "Files['HIVSeqDBHepler.fasta'] = {'filePath': './data/HIVBrainSeqDB/HIVSeqDBHepler.fasta'}\n",
    "Files['HIVSeqDB.fasta'] = {'filePath': './data/HIVBrainSeqDB/HIVSeqDB.fasta'}\n",
    "Files['HAD.fas'] = {'filePath': './data/HolmanAndGabuzda/HAD.fas'}\n",
    "\n",
    "for file in Files:\n",
    "    with open(Files[file][\"filePath\"]) as fasta_file:\n",
    "        ids = []\n",
    "        sequences = []\n",
    "        for title, sequence in SimpleFastaParser(fasta_file):\n",
    "            ids.append(title.split(None, 1)[0])  # First word is ID\n",
    "            sequences.append(sequence)\n",
    "        Files[file][\"ids\"] = ids\n",
    "        Files[file][\"sequences\"] = sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanvelazquez/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (5,7,16,25,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/ryanvelazquez/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Load the metadata.\n",
    "OgishiMetadata = pd.read_csv('./data/OgishiAndYotsuyanagi/Metadataset.csv')\n",
    "OgishiHANDDBMetadata = pd.read_csv('./data/OgishiAndYotsuyanagi/HANDDatabase.csv')\n",
    "OgishiLANLMetadata = pd.read_csv('./data/OgishiAndYotsuyanagi/LANL.csv')\n",
    "HolmanTestHADValues = pd.read_csv('./data/HIVBrainSeqDB/HAD.csv')\n",
    "HolmanTrainMetadata = pd.read_csv('./data/HolmanAndGabuzda/HolmanTrain.csv')\n",
    "HolmanTestMetadata = pd.read_csv('./data/HolmanAndGabuzda/HolmanTest.csv')\n",
    "HIVSeqDBMetadata = pd.DataFrame.from_csv('./data/HIVBrainSeqDB/HIVSeqDB-MetaData.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='combine'></a>\n",
    "## 2. Combine all of the Data into one Comprehensive Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ogishi'></a>\n",
    "### 2a. Combine all the Ogishi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasta files.\n",
    "OgishiFasta = pd.DataFrame({\n",
    "    'Accession': Files['C2V3C3_Metadataset_AA.fasta']['ids'],\n",
    "    'AASequence1': Files['C2V3C3_Metadataset_AA.fasta']['sequences']})\n",
    "OgishiDBFasta = pd.DataFrame({\n",
    "    'Accession': Files['C2V3C3_HANDDatabase_AA.fasta']['ids'],\n",
    "    'AASequence2': Files['C2V3C3_HANDDatabase_AA.fasta']['sequences']})\n",
    "OgishiLANLFasta = pd.DataFrame({\n",
    "    'Accession': Files['C2V3C3_LANL_AA.fasta']['ids'],\n",
    "    'AASequence3': Files['C2V3C3_LANL_AA.fasta']['sequences']})\n",
    "\n",
    "# csv files.\n",
    "OgishiHANDDBMetadata.rename(index=str, columns={'Sequence: Accession Number': 'Accession'}, inplace=True)\n",
    "\n",
    "# Set the Accession as the index for all the Ogishi dataframes\n",
    "OgishiDFs = [OgishiFasta, OgishiDBFasta, OgishiLANLFasta, OgishiMetadata, OgishiHANDDBMetadata, OgishiLANLMetadata]\n",
    "for DF in OgishiDFs:\n",
    "    DF.set_index('Accession', inplace=True)\n",
    "    \n",
    "# Combine into one DF\n",
    "OgishiCombinedDF = reduce(lambda left,right: pd.merge(left,right, on='Accession', how='outer'), OgishiDFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='brain_db'></a>\n",
    "### 2b. Add the HIV Brain Sequence Database Data \n",
    "(the Holman training data is a subset of this data so we don't need to add it separately)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequences.\n",
    "HIVSeqFasta = pd.DataFrame({\n",
    "    'Accession': Files['HIVSeqDB.fasta']['ids'],\n",
    "    'NASequenceBrainDB': Files['HIVSeqDB.fasta']['sequences']})\n",
    "HIVSeqFasta.set_index('Accession', inplace=True)\n",
    "\n",
    "# Add that data into the combined DF\n",
    "DFsToCombine = [OgishiCombinedDF, HIVSeqFasta, HIVSeqDBMetadata]\n",
    "OgishiAndHIVBrainDBCombined = reduce(lambda left,right: pd.merge(left,right, on='Accession', how='outer'), DFsToCombine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='holman'></a>\n",
    "### 2c. Add the Holman Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequences.\n",
    "HolmanValidationFasta = pd.DataFrame({\n",
    "    'Accession': Files['HAD.fas']['ids'],\n",
    "    'NASequence': Files['HAD.fas']['sequences']})\n",
    "\n",
    "# Metadata. From the paper we know that this dataset, \n",
    "# \"consists of virus sampled fro the brain of 10 independent HAD patients\".\n",
    "# So we will add a column for \"Sample Tissue Name\" (Brain), \"Neurocognitive Diagnosis\" (HAD), etc.\n",
    "HolmanValidationFasta['Neurocognitive diagnosis'] = 'HAD: severity not specified'\n",
    "HolmanValidationFasta['Sample Tissue Name'] = 'Brain'\n",
    "HolmanValidationFasta['Sample Tissue Class'] = 'Brian, brainstem, and spinal chord'\n",
    "\n",
    "# Get and set unique patient IDs based on the sequence ID, which we are refering to as Accession.\n",
    "def extractPatientID(row):\n",
    "   return row['Accession'].split('_')[0]\n",
    "HolmanValidationFasta['Patient'] = HolmanValidationFasta.apply(lambda row: extractPatientID(row), axis=1)\n",
    "\n",
    "HolmanValidationFasta.set_index('Accession', inplace=True)\n",
    "\n",
    "# Add that data into the combined DF\n",
    "combinedDF = pd.merge(OgishiAndHIVBrainDBCombined, HolmanValidationFasta, on='Accession', how='outer')\n",
    "combinedDF.set_index('Accession', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"new_cols\"></a>\n",
    "## 3. Add New Columns to Summarize and Concatenate Pertinant Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111254, 106)\n",
      "['AASequence1', 'AASequence2', 'AASequence3', 'Clinical.Status', 'Reference_PublicationYear', 'Reference_FirstAuthor', 'Reference_PMID', 'LANL_Pub.id', 'LANL_SE.id', 'LANL_Patient.Id', 'Patient.Sex', 'Number.of.patient.seqs', 'Georegion_x', 'Coreceptor_x', 'Sample.Tissue', 'Culture.Method', 'Viral.load', 'CD4.count', 'CD8.count', 'Days.from.Infection', 'Days.from.Seroconversion', 'Sequence_x', 'Patient: Code', 'Patient: HAND Status', 'Patient: Sex', 'Patient: Risk Factor', 'Patient: Viral Load At Sampling', 'Patient: CD4 Count At Sampling', 'Patient: HIV Therapy Status', 'Patient HIV Therapy Months', 'Patient: Age At Sampling', 'Patient Health At Sampling', 'Sampling: Year', 'Sampling Region', 'Sampling: Tissue', 'Sequence: Polyprotein (Protein)', 'Genotyping Information', 'SEQUENCE PMID', 'Sequence Length (nt)', 'HIV Sequence', 'SE id(SPL)', 'PUB id(SPL)', 'SE id(SA)', 'Patient Id', 'Patient Sex_x', 'Risk Factor', 'Infection Country', 'Project', 'Patient ethnicity', 'SE id(SSAM)', 'PAT id(SSAM)', 'Georegion_y', 'Country', 'Patient Age_x', 'Subtype', 'Phenotype', 'Coreceptor_y', 'Sample Tissue', 'Culture Method', 'Molecule type', 'Drug Naive_x', 'Viral load', 'CD4 count', 'CD8 count', 'Days from Infection', 'Days from Seroconversion', 'Days from first Sample', 'Sequencing method', 'Amplification strategy', 'Days from treatment start', 'Days from treatment end', 'Vaccine status', 'PUB id', 'Pubmed ID', 'Sequence_y', 'NASequenceBrainDB', 'Sample Tissue Code', 'Sample Tissue Class_x', 'Nucleic Acid Type', 'Sample Country', 'Sample City', 'Patient Age_y', 'Heath Status', 'Drug Naive_y', 'Antiretroviral Treatment', 'Viral Load Plasma', 'Viral Load Brain', 'Viral Load Lymphoid', 'CD4 Count', 'Neuropathological diagnosis', 'Neurocognitive diagnosis_x', 'Patient Code', 'Patient Sex_y', 'Patient Risk Factor', 'Patient Year of Death', 'Publication', 'PubMed Id', 'Publication Title', 'Sequence Start', 'Sequence Stop', 'Unnamed: 26', 'NASequence', 'Neurocognitive diagnosis_y', 'Sample Tissue Name', 'Sample Tissue Class_y', 'Patient']\n"
     ]
    }
   ],
   "source": [
    "# A dictonary may be a bit more usable for some of this.\n",
    "combinedDict = combinedDF.to_dict(orient='index')\n",
    "# We will create new columns add add them to \"columnsToKeep\" as we go.\n",
    "columns = list(combinedDF.columns)\n",
    "columnsToKeep = []\n",
    "if verbose:\n",
    "    print(combinedDF.shape)\n",
    "    print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sequences'></a>\n",
    "### 3a. Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AASequence1', 'AASequence2', 'AASequence3', 'Number.of.patient.seqs', 'Sequence_x', 'Sequence: Polyprotein (Protein)', 'SEQUENCE PMID', 'Sequence Length (nt)', 'HIV Sequence', 'Sequencing method', 'Sequence_y', 'NASequenceBrainDB', 'Sequence Start', 'Sequence Stop', 'NASequence']\n"
     ]
    }
   ],
   "source": [
    "columnsSeq = [seq for seq in columns if 'seq' in seq or 'Seq' in seq or 'SEQ' in seq]\n",
    "if verbose:\n",
    "    print(columnsSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make sure all the sequences that should match do match\n",
    "AASeqColumns = ['AASequence1', 'AASequence2', 'AASequence3']\n",
    "NASeqColumns = ['Sequence_x', 'HIV Sequence', 'Sequence_y', 'NASequence', 'NASequenceBrainDB']\n",
    "\n",
    "def ConfirmSeqsAgreeAndAppendCorrectOne(colList, AAorNA):\n",
    "    for key in combinedDict:\n",
    "        data = combinedDict[key]\n",
    "        Agree = True\n",
    "        nonNullSeqs = []\n",
    "        \n",
    "        for col in colList:\n",
    "            # If the sequence is a string of length greater than one.\n",
    "            if isinstance(data[col], str):\n",
    "                if len(list(data[col])) > 1:\n",
    "                    # convert it to lowercase and (if it's a Nucleic Acid) replace 'u' with 't'.\n",
    "                    seq = data[col].lower()\n",
    "                    if AAorNA == 'NA':\n",
    "                        def u2t(letter):\n",
    "                            if letter == 'u':\n",
    "                                return 't'\n",
    "                            else:\n",
    "                                return letter\n",
    "                        convertedSeqList = [u2t(x) for x in list(seq)]\n",
    "                        seq = ''.join(convertedSeqList)\n",
    "                     \n",
    "                    nonNullSeqs.append(seq)\n",
    "            \n",
    "            # Test to make sure the sequences match, i.e. only one value in the set.\n",
    "            UniqueNonNullSeqs = list(set(nonNullSeqs))\n",
    "            if len(UniqueNonNullSeqs) > 1:\n",
    "                # If they don't match is one sequence a subset of the other (I already tested to confirm that there are only two in each)?\n",
    "                if len(UniqueNonNullSeqs[0]) < len(UniqueNonNullSeqs[1]):\n",
    "                    shortSeq, longSeq = UniqueNonNullSeqs[0], UniqueNonNullSeqs[1]\n",
    "                else:\n",
    "                    shortSeq, longSeq = UniqueNonNullSeqs[1], UniqueNonNullSeqs[0]\n",
    "                if shortSeq not in longSeq:\n",
    "                    # Here's where we would see (and call out) that there are conflicting sequences for the same sample.\n",
    "                    Agree = False\n",
    "                \n",
    "                # Add the correct sequence to a column\n",
    "                combinedDict[key]['seq_', AAorNA] = longSeq\n",
    "            else:\n",
    "                #print(UniqueNonNullSeqs)\n",
    "                if len(UniqueNonNullSeqs) > 0:\n",
    "                    combinedDict[key]['seq_' + AAorNA] = UniqueNonNullSeqs[0]\n",
    "                else:\n",
    "                    combinedDict[key]['seq_' + AAorNA] = None\n",
    "            \n",
    "            # Add a column for whether or not the sequences Agree (False if there are conflicting sequences for the same sample).\n",
    "            combinedDict[key][AAorNA] = Agree\n",
    "\n",
    "ConfirmSeqsAgreeAndAppendCorrectOne(AASeqColumns, 'AA')\n",
    "ConfirmSeqsAgreeAndAppendCorrectOne(NASeqColumns, 'NA')\n",
    "\n",
    "if verbose:\n",
    "   for key in combinedDict:\n",
    "    #print(combinedDict[key]['AA'])\n",
    "    if combinedDict[key]['AA'] is False:\n",
    "        print('AA Seqs dont match')\n",
    "    if combinedDict[key]['NA'] is False:\n",
    "        print('NA Seqs dont match')\n",
    "        \n",
    "# No conflicting sequences! We'll add a column for DNA seqs and a column for Amino Acid seqs.\n",
    "columnsToKeep.extend(['seq_AA', 'seq_NA'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hand_status'></a>\n",
    "### 3b. HAND Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clinical.Status', 'Patient: HAND Status', 'Neuropathological diagnosis', 'Neurocognitive diagnosis_x', 'Neurocognitive diagnosis_y']\n"
     ]
    }
   ],
   "source": [
    "substringList = ['had', 'HAD', 'hand', 'HAND', 'Neuro', 'neuro', 'clinic', 'Clinic']\n",
    "columnsHAND = [seq for seq in columns if any(substring in seq for substring in substringList)]\n",
    "if verbose:\n",
    "    print(columnsHAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AppendHANDStatusSubFunction(key, UniqueNonNullHANDStatus):\n",
    "    # We will use the \"one-hot-encoding\" style for dealing with the HAND status info.\n",
    "    # There are many different ways this info could be parsed out...\n",
    "    # I've tried to logically subdivide the classifications but this could certianly impact downstream analyses.\n",
    "    noHANDInclusive = ['No HAND', 'NonHAND']\n",
    "    HADInclusive = ['HAD', 'HAD: severity not specified', 'HAD + HIVE', 'HAD: mild', 'HAD: moderate', 'HAD: severe', 'HAD: severity not specified', ]\n",
    "    HANDInclusive = ['HAND']\n",
    "    ADCInclusive = ['ADC', 'ADC + HIVE']\n",
    "    HIVEInclusive = ['HIVE', 'ADC + HIVE', 'Acute HIV encephalopathy', 'HAD + HIVE', 'HIVE: mild', 'HIVE: moderate', 'HIVE: severe', 'HIVE: severity not specified']\n",
    "    OtherInclusive = ['Other: Alzheimer type 2 gliosis, Focal (territorial) infarct.', 'Other: CMV encephalitis', 'Other: CNS lymphoma', 'Other: cerebral atrophy', 'Other: necrotizing encephalitis, not HIV-related', 'Other: progressive multifocal leukoencephalopathy', 'Other: toxoplasmosis', 'Other: widespread atherosclerosis']\n",
    "    UnknownInclusive = ['Unknown HAND Status', 'Unknown diagnosis']\n",
    "    NPDInclusive = ['NPD']\n",
    "    RemainingInclusive = ['Lymphocytic perivascular cuffing', 'MCMD', 'NPI: unknown']\n",
    "    \n",
    "    if any(substring in UniqueNonNullHANDStatus for substring in noHANDInclusive):\n",
    "        combinedDict[key]['Inclusive_NoHAND'] = True\n",
    "    if any(substring in UniqueNonNullHANDStatus for substring in HADInclusive):\n",
    "        combinedDict[key]['Inclusive_HAD'] = True\n",
    "    if any(substring in UniqueNonNullHANDStatus for substring in HANDInclusive):\n",
    "        combinedDict[key]['Inclusive_HAND'] = True\n",
    "    if any(substring in UniqueNonNullHANDStatus for substring in ADCInclusive):\n",
    "        combinedDict[key]['Inclusive_ADC'] = True\n",
    "    if any(substring in UniqueNonNullHANDStatus for substring in HIVEInclusive):\n",
    "        combinedDict[key]['Inclusive_HIVE'] = True\n",
    "    if any(substring in UniqueNonNullHANDStatus for substring in OtherInclusive):\n",
    "        combinedDict[key]['Inclusive_Other'] = True\n",
    "    if any(substring in UniqueNonNullHANDStatus for substring in UnknownInclusive):\n",
    "        combinedDict[key]['Inclusive_Unknown'] = True\n",
    "    if any(substring in UniqueNonNullHANDStatus for substring in NPDInclusive):\n",
    "        combinedDict[key]['Inclusive_NPD'] = True\n",
    "    if any(substring in UniqueNonNullHANDStatus for substring in RemainingInclusive):\n",
    "        combinedDict[key]['Inclusive_Remaining'] = True      \n",
    "        \n",
    "def AppendHANDStatus(colList):\n",
    "    for key in combinedDict:\n",
    "        data = combinedDict[key]\n",
    "        nonNullHANDStatus = []\n",
    "        \n",
    "        for col in colList:\n",
    "            # If the value is a string of length greater than one.\n",
    "            if isinstance(data[col], str):\n",
    "                if len(list(data[col])) > 1:\n",
    "                    nonNullHANDStatus.append(data[col])\n",
    "\n",
    "        UniqueNonNullHANDStatus = list(set(nonNullHANDStatus))\n",
    "        AppendHANDStatusSubFunction(key, UniqueNonNullHANDStatus)\n",
    "\n",
    "AppendHANDStatus(columnsHAND)\n",
    "\n",
    "columnsToKeep.extend(['Inclusive_NoHAND', 'Inclusive_HAD', 'Inclusive_HAND', 'Inclusive_ADC', 'Inclusive_HIVE', 'Inclusive_Other', 'Inclusive_Unknown', 'Inclusive_NPD', 'Inclusive_Remaining'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tissue_id'></a>\n",
    "### 3c. Tissue ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sample.Tissue', 'Sampling: Tissue', 'Sample Tissue', 'Sample Tissue Code', 'Sample Tissue Class_x', 'Sample Tissue Name', 'Sample Tissue Class_y']\n"
     ]
    }
   ],
   "source": [
    "substringList = ['Tissue']\n",
    "columnsTissue = [seq for seq in columns if any(substring in seq for substring in substringList)]\n",
    "if verbose:\n",
    "    print(columnsTissue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AppendTissueInfoSubFunction(key, UniqueNonNullTissue):\n",
    "    # Again, many different ways this info could be sliced up and parsed.\n",
    "    # As of the data munging phase, I don't forsee needing fine-grained tissue info so I'm keeping it very simple for now.\n",
    "    classified = False\n",
    "    Brain = ['Brain', 'brain', 'Choroid Plexus']\n",
    "    CNS = Brain + ['Brain, brainstem, and spinal cord','Brian, brainstem, and spinal chord', 'CSF', 'Meninges, choroid plexus, and CSF', 'Spinal Cord', 'Meninges', 'meninges', 'spinal cord']\n",
    "\n",
    "    if any(substring in UniqueNonNullTissue for substring in Brain):\n",
    "        combinedDict[key]['Tissue_Brain'] = True\n",
    "        classified = True\n",
    "    if any(substring in UniqueNonNullTissue for substring in CNS):\n",
    "        combinedDict[key]['Tissue_CNS'] = True\n",
    "        classified = True\n",
    "    if not classified:\n",
    "        combinedDict[key]['Tissue_Other'] = True\n",
    "\n",
    "def AppendTissueInfo(colList):\n",
    "    # TODO: some of the sample may only have FMA codes... I'm just lumping all these into the Tissue_Other right now.\n",
    "    for key in combinedDict:\n",
    "        data = combinedDict[key]\n",
    "        nonNullTissue = []\n",
    "        \n",
    "        for col in colList:\n",
    "            # If the tissue is a string of length greater than one.\n",
    "            if isinstance(data[col], str):\n",
    "                if len(list(data[col])) > 1:   \n",
    "                    nonNullTissue.append(data[col])\n",
    "            \n",
    "            UniqueNonNullTissue = list(set(nonNullTissue))\n",
    "            AppendTissueInfoSubFunction(key, UniqueNonNullTissue)\n",
    "                        \n",
    "AppendTissueInfo(columnsTissue)\n",
    "\n",
    "columnsToKeep.extend(['Tissue_Brain', 'Tissue_CNS', 'Tissue_other'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='patient_id'></a>\n",
    "### 3d. Patient ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reference_PublicationYear', 'Reference_PMID', 'LANL_Pub.id', 'LANL_SE.id', 'LANL_Patient.Id', 'Patient.Sex', 'Patient: Code', 'Patient: HAND Status', 'Patient: Sex', 'Patient: Risk Factor', 'Patient: Viral Load At Sampling', 'Patient: CD4 Count At Sampling', 'Patient: HIV Therapy Status', 'Patient HIV Therapy Months', 'Patient: Age At Sampling', 'Patient Health At Sampling', 'SEQUENCE PMID', 'SE id(SPL)', 'PUB id(SPL)', 'SE id(SA)', 'Patient Id', 'Patient Sex_x', 'Patient ethnicity', 'SE id(SSAM)', 'PAT id(SSAM)', 'Patient Age_x', 'PUB id', 'Pubmed ID', 'Patient Age_y', 'Patient Code', 'Patient Sex_y', 'Patient Risk Factor', 'Patient Year of Death', 'Publication', 'PubMed Id', 'Publication Title', 'Patient']\n"
     ]
    }
   ],
   "source": [
    "substringList = ['PMID','SE.id', 'Patient.Id', 'Patient: Code', 'SE id', 'Patient Id', 'PAT id', 'Pub', 'PUB', 'Patient']\n",
    "columnsOther = [seq for seq in columns if any(substring in seq for substring in substringList)]\n",
    "if verbose:\n",
    "    print(columnsOther)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PatientIDCols = ['LANL_Patient.Id', 'Patient: Code', 'Patient Id', 'PAT id(SSAM)', 'Patient Code', 'Patient']\n",
    "def AppendPatientID(colList):\n",
    "    for key in combinedDict:\n",
    "        data = combinedDict[key]\n",
    "        nonNullPatientID = []\n",
    "        \n",
    "        for col in colList:\n",
    "            if isinstance(data[col], str):\n",
    "                if len(list(data[col])) > 1:                    \n",
    "                    nonNullPatientID.append(data[col])\n",
    "            \n",
    "            UniqueNonNullPatientID = list(set(nonNullPatientID))\n",
    "            if len(UniqueNonNullPatientID) == 2:\n",
    "                # If they don't match is one a subset of the other (I already tested to confirm that there are only two in each)?\n",
    "                if len(UniqueNonNullPatientID[0]) < len(UniqueNonNullPatientID[1]):\n",
    "                    short, long = UniqueNonNullPatientID[0], UniqueNonNullPatientID[1]\n",
    "                else:\n",
    "                    short, long = UniqueNonNullPatientID[1], UniqueNonNullPatientID[0]\n",
    "                # See if they are basically the same ID just flipped around an underscore (i.e. 'NA21_UK1' & 'UK1_NA21')\n",
    "                first, second = 'dont', 'match'\n",
    "                if len(UniqueNonNullPatientID[0].split('_'))==2 and len(UniqueNonNullPatientID[1].split('_'))==2:\n",
    "                    first = UniqueNonNullPatientID[0].split('_')[0]\n",
    "                    second = UniqueNonNullPatientID[1].split('_')[1]\n",
    "                \n",
    "                if short in long:\n",
    "                    combinedDict[key]['ID_Patient'] = long\n",
    "                # See if they are basically the same ID just flipped around an underscore (i.e. 'NA21_UK1' & 'UK1_NA21')\n",
    "                elif first == second:\n",
    "                    combinedDict[key]['ID_Patient'] = UniqueNonNullPatientID[0]\n",
    "                # Deal with 'subject 4' & 'SUBJECT_4'.\n",
    "                elif UniqueNonNullPatientID[0] == 'subject 4':\n",
    "                    combinedDict[key]['ID_Patient'] = 'subject 4'             \n",
    "                elif UniqueNonNullPatientID[0] == 'HADpatient' or UniqueNonNullPatientID[1] == 'HADpatient':\n",
    "                    combinedDict[key]['ID_Patient'] = 'HADpatientID'\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        print ('Unable to reconcile IDs: ', key)\n",
    "            \n",
    "            elif len(UniqueNonNullPatientID) == 1:\n",
    "                combinedDict[key]['ID_Patient'] = UniqueNonNullPatientID[0]\n",
    "                \n",
    "                        \n",
    "AppendPatientID(PatientIDCols)\n",
    "\n",
    "columnsToKeep.extend(['ID_Patient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reduce'></a>\n",
    "## 4. Reduce to only the Data We Want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the columns we want.\n",
    "filteredCombinedDict = {}\n",
    "for key in combinedDict:\n",
    "    entry = combinedDict[key]\n",
    "    columnsToKeepInEntry = [colName for colName in columnsToKeep if colName in list(entry.keys())]\n",
    "    filteredEntry = { columnToKeep: entry[columnToKeep] for columnToKeep in columnsToKeepInEntry }\n",
    "    filteredCombinedDict[key] = filteredEntry\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filtered dataset has:  111254  Entries\n",
      "The reduced dataset has:  5600  Entries\n"
     ]
    }
   ],
   "source": [
    "# Only keep the rows we want (only rows that have meaningful HAND Status, and, potentially, Patient_ID).\n",
    "# TODO: see if we can address the ~ 2,500 sequences that don't have a value for 'ID_Patient'\n",
    "reducedCombinedDict = {}\n",
    "for key in filteredCombinedDict:\n",
    "    entry = filteredCombinedDict[key]\n",
    "    entryColumns = list(entry.keys())\n",
    "    # The list below doesn't include sequences that only have: ['Inclusive_Other', 'Inclusive_Unknown', 'Inclusive_NPD', 'Inclusive_Remaining']\n",
    "    SpecificHANDDesignations = ['Inclusive_NoHAND', 'Inclusive_HAD', 'Inclusive_HAND', 'Inclusive_ADC', 'Inclusive_HIVE']\n",
    "    \n",
    "    includeEntry = False\n",
    "    for item in entryColumns:\n",
    "        if item in SpecificHANDDesignations:\n",
    "           includeEntry = True\n",
    "    if 'ID_Patient' not in entryColumns:\n",
    "        includeEntry = False\n",
    "    if includeEntry:\n",
    "        reducedCombinedDict[key] = entry\n",
    "        \n",
    "if verbose:\n",
    "    print('The filtered dataset has: ', len(list(filteredCombinedDict.keys())), ' Entries')\n",
    "    print('The reduced dataset has: ', len(list(reducedCombinedDict.keys())), ' Entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filtered dataset has:  111254  Entries\n",
    "The reduced dataset has:  8112  Entries (when not removing entries that don't have patient_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='save'></a>\n",
    "## 5. Save the Data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of the full combined dataset for potential later use.\n",
    "combinedDF.to_csv('./data/comprehensive_combined_data.csv')\n",
    "\n",
    "# Save the prepared/munged/filtered/reduced dataset.\n",
    "mungedDF = pd.DataFrame.from_dict(reducedCombinedDict, orient='index')\n",
    "mungedDF.to_csv('./data/combined_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
